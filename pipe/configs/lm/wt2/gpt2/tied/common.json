{
    "logdir": "logs/debug/",
    "data_dir": "/home_local/saareliad/data",
    "out_dir": "results/lm/gpt2/tied/",
    "auto_file_name": true,
    "out_filename": "tied",
    "distributed_backend": "mpi",
    "model": "gpt2_p4_lm_tied",
    "stage_to_device_map": [0, 1, 2, 3, 0],
    "model_name_or_path": "gpt2",
    "dataset": "wt2",
    "statistics": "lm_loss_per_batch",
    "trainer": {
        "type": "lm",
        "args": {
        }
    },
    "bs_train": 4,
    "bs_test": 4,
    "train_seq_len": 1024,
    "valid_seq_len": 1024,
    "test_seq_len": 1024,
    "num_data_workers": 10,
    "optimizer": {
        "type": "adamw",
        "args": {
            "lr": 5e-5,
            "weight_decay": 0,
            "eps": 1e-8
        }
    },
    "lr_scheduler": {
        "type": "get_linear_schedule_with_warmup",
        "preproc_args": {
            "num_training_steps": "epochs_to_steps",
            "num_warmup_steps": "epochs_to_steps"
        },
        "args": {
            "num_warmup_steps": 0,
            "num_training_steps": -1,
            "last_epoch": -1
        }
    },
    "epochs": 3,
    "steps": -1,
    "seed_from_cmd": true,
    "num_chunks": 1,
    "verbose_comm": false,
    "flush_rate": -1,
    "work_scheduler": "1F1B",
    "cudnn_benchmark": true,
    "max_buffers": 1,
    "step_every": 1,
    "train_batches_limit": -1,
    "log_frequency": 20,
    "overwrite_cache": true,
    "keep_buffers_alive": false,
    "dont_drop_last": true,
    "stateless_tied": true,
    "nprocs": 5
}
