graph(%self.1 : __torch__.torch.nn.modules.module.___torch_mangle_82.Module,
      %input.1 : Float(100, 100)):
  %85 : __torch__.torch.nn.modules.module.___torch_mangle_81.Module = prim::GetAttr[name="b2"](%self.1)
  %75 : __torch__.torch.nn.modules.module.___torch_mangle_73.Module = prim::GetAttr[name="b1"](%self.1)
  %116 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%75, %input.1)
  %105 : Tensor, %106 : Tensor = prim::TupleUnpack(%116)
  %118 : __torch__.torch.nn.modules.module.___torch_mangle_80.Module = prim::GetAttr[name="op"](%85)
  %119 : __torch__.torch.nn.modules.module.___torch_mangle_75.Module = prim::GetAttr[name="l0"](%85)
  %120 : __torch__.torch.nn.modules.module.___torch_mangle_74.Module = prim::GetAttr[name="act"](%119)
  %121 : Tensor = prim::CallMethod[name="forward"](%120, %105)
  %122 : Long() = prim::Constant[value={5}](), scope: __module.b2/__module.b2.l0 # feature_test.py:57:0
  %input : Float(100, 100) = aten::mul(%121, %122), scope: __module.b2/__module.b2.l0 # feature_test.py:57:0
  %124 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%118, %106, %input)
  %125 : Tensor, %126 : Tensor = prim::TupleUnpack(%124)
  %127 : (Tensor, Tensor, Tensor) = prim::TupleConstruct(%125, %126, %input)
  %113 : Tensor, %114 : Tensor, %115 : Tensor = prim::TupleUnpack(%127)
  %54 : (Float(100, 100), Float(100, 100)) = prim::TupleConstruct(%113, %114)
  %55 : ((Float(100, 100), Float(100, 100)), Float(100, 100)) = prim::TupleConstruct(%54, %115)
  return (%55)
