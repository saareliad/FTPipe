{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlp\n",
    "import torch\n",
    "import operator\n",
    "from torch.utils.data import TensorDataset\n",
    "import transformers\n",
    "from transformers import T5Tokenizer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/saareliad/workspace/async_pipeline\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioned_model_path = \"models/partitioned/t5_small_tied_lmhead_4p_bw12_async_squad1.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_internal_transformer_config(partitioned_model_path):\n",
    "    basename = os.path.basename(partitioned_model_path)\n",
    "    if basename.endswith(\".py\"):\n",
    "        basename = basename[:-3]\n",
    "    return basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_transformer_config = get_internal_transformer_config(partitioned_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'missing_keys': ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'], 'error_msgs': []}\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer, config = models.transformers_utils.get_model_tokenizer_and_config_by_name(internal_transformer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# T5 preprocessing\n",
    "######################\n",
    "# moving the preprocessing from the model outside.\n",
    "# (its problematic for pipeline to do preprocessing inside the model)\n",
    "\n",
    "def is_None(a):\n",
    "    return operator.is_(a, None)\n",
    "\n",
    "\n",
    "def is_not_None(a):\n",
    "    return operator.is_not(a, None)\n",
    "\n",
    "\n",
    "# Used to be a method. changed to just take it from config.\n",
    "def _shift_right(config, input_ids):\n",
    "    decoder_start_token_id = config.decoder_start_token_id\n",
    "    pad_token_id = config.pad_token_id\n",
    "\n",
    "    assert (\n",
    "        # NOTE is not None\n",
    "        # decoder_start_token_id is not None\n",
    "        is_not_None(decoder_start_token_id)\n",
    "    ), \"self.model.config.decoder_start_token_id has to be defined. In T5 it is usually set to the pad_token_id. See T5 docs for more information\"\n",
    "\n",
    "    # shift inputs to the right\n",
    "    shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n",
    "    shifted_input_ids[..., 1:] = input_ids[..., :-1].clone()\n",
    "    shifted_input_ids[..., 0] = decoder_start_token_id\n",
    "\n",
    "    #NOTE is not None\n",
    "    # assert pad_token_id is not None, \"self.model.config.pad_token_id has to be defined.\"\n",
    "    assert is_not_None(pad_token_id),\"self.model.config.pad_token_id has to be defined.\"\n",
    "    # replace possible -100 values in lm_labels by `pad_token_id`\n",
    "    shifted_input_ids.masked_fill_(shifted_input_ids == -100, pad_token_id)\n",
    "\n",
    "    assert torch.all(shifted_input_ids >= 0).item(), \"Verify that `lm_labels` has only positive values and -100\"\n",
    "\n",
    "    return shifted_input_ids\n",
    "\n",
    "\n",
    "\n",
    "################################################\n",
    "# mask methods extracted from transformers.PreTrainedModel\n",
    "# in order to enable precomputing of masks\n",
    "################################################\n",
    "\n",
    "\n",
    "def get_attention_mask(input_shape,attention_mask,device,is_decoder=False,dtype=torch.float32):\n",
    "    # attention_mask is the original decoder/encoder attention mask given to the model\n",
    "    # for encoder we will pass input_ids.size() and attention_mask\n",
    "    # for decoder we will pass decoder_input_ids.size() and decoder_attention_mask\n",
    "    if is_None(attention_mask):\n",
    "        attention_mask = torch.ones(input_shape,device=device)\n",
    "\n",
    "    # ourselves in which case we just need to make it broadcastable to all heads.    \n",
    "    return get_extended_attention_mask(attention_mask, input_shape,is_decoder=is_decoder,dtype=dtype)\n",
    "\n",
    "def get_inverted_encoder_attention_mask(mask_shape,encoder_attention_mask,device,dtype=torch.float32):\n",
    "    # mask_shape is batch_size,encoder_seq_length\n",
    "    # encoder_attention_mask is the original attention_mask given to the model\n",
    "    if is_None(encoder_attention_mask):\n",
    "        encoder_attention_mask = torch.ones(mask_shape,device=device)\n",
    "\n",
    "    if is_not_None(encoder_attention_mask):\n",
    "        inverted_encoder_attention_mask = invert_attention_mask(encoder_attention_mask,dtype=dtype)\n",
    "    else:\n",
    "        inverted_encoder_attention_mask = None\n",
    "    \n",
    "    return inverted_encoder_attention_mask\n",
    "\n",
    "\n",
    "\n",
    "def invert_attention_mask(encoder_attention_mask,dtype=torch.float32):\n",
    "    \"\"\"type: torch.Tensor -> torch.Tensor\"\"\"\n",
    "    if encoder_attention_mask.dim() == 3:\n",
    "        encoder_extended_attention_mask = encoder_attention_mask[:, None, :, :]\n",
    "    if encoder_attention_mask.dim() == 2:\n",
    "        encoder_extended_attention_mask = encoder_attention_mask[:, None, None, :]\n",
    "    # T5 has a mask that can compare sequence ids, we can simulate this here with this transposition\n",
    "    # Cf. https://github.com/tensorflow/mesh/blob/8d2465e9bc93129b913b5ccc6a59aa97abd96ec6/mesh_tensorflow\n",
    "    # /transformer/transformer_layers.py#L270\n",
    "    # encoder_extended_attention_mask = (encoder_extended_attention_mask ==\n",
    "    # encoder_extended_attention_mask.transpose(-1, -2))\n",
    "    encoder_extended_attention_mask = encoder_extended_attention_mask.to(dtype=dtype)  # fp16 compatibility\n",
    "\n",
    "    if dtype == torch.float16:\n",
    "        encoder_extended_attention_mask = (1.0 - encoder_extended_attention_mask) * -1e4\n",
    "    elif dtype == torch.float32:\n",
    "        encoder_extended_attention_mask = (1.0 - encoder_extended_attention_mask) * -1e9\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"{} not recognized. `dtype` should be set to either `torch.float32` or `torch.float16`\".format(\n",
    "                dtype\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return encoder_extended_attention_mask\n",
    "\n",
    "\n",
    "def get_extended_attention_mask(attention_mask, input_shape,is_decoder=False,dtype=torch.float32):\n",
    "    \"\"\"Makes broadcastable attention mask and causal mask so that future and maked tokens are ignored.\n",
    "\n",
    "    Arguments:\n",
    "        attention_mask: torch.Tensor with 1 indicating tokens to ATTEND to\n",
    "        input_shape: tuple, shape of input_ids\n",
    "        device: torch.Device, usually self.device\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor with dtype of attention_mask.dtype\n",
    "    \"\"\"\n",
    "    # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
    "    # ourselves in which case we just need to make it broadcastable to all heads.\n",
    "    if attention_mask.dim() == 3:\n",
    "        extended_attention_mask = attention_mask[:, None, :, :]\n",
    "    elif attention_mask.dim() == 2:\n",
    "        # Provided a padding mask of dimensions [batch_size, seq_length]\n",
    "        # - if the model is a decoder, apply a causal mask in addition to the padding mask\n",
    "        # - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
    "        if is_decoder:\n",
    "            batch_size, seq_length = input_shape\n",
    "            seq_ids = torch.arange(seq_length,device=attention_mask.device)\n",
    "            causal_mask = seq_ids[None, None, :].repeat(batch_size, seq_length, 1) <= seq_ids[None, :, None]\n",
    "            # causal and attention masks must have same type with pytorch version < 1.3\n",
    "            causal_mask = causal_mask.to(attention_mask.dtype)\n",
    "            extended_attention_mask = causal_mask[:, None, :, :] * attention_mask[:, None, None, :]\n",
    "        else:\n",
    "            extended_attention_mask = attention_mask[:, None, None, :]\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\".format(\n",
    "                input_shape, attention_mask.shape\n",
    "            )\n",
    "        )\n",
    "    # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
    "    # masked positions, this operation will create a tensor which is 0.0 for\n",
    "    # positions we want to attend and -10000.0 for masked positions.\n",
    "    # Since we are adding it to the raw scores before the softmax, this is\n",
    "    # effectively the same as removing these entirely.\n",
    "    extended_attention_mask = extended_attention_mask.to(dtype=dtype)  # fp16 compatibility\n",
    "    extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "    return extended_attention_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-0.8355,  0.5072, -1.0405]),\n",
       " tensor([-1.1658, -1.1889, -1.3526]),\n",
       " tensor([-2.0628, -0.9773, -0.6298]),\n",
       " tensor([-1.1769, -0.2107,  0.5137])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(4,3)\n",
    "\n",
    "list(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "just = ['attention_mask', 'decoder_input_ids', 'input_ids']\n",
    "\n",
    "just = ['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02216df43e244e48b2d6f4a2e12f37ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=876.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a099efeb2b284fd192b6bc3341ad926f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1315d25a950d4de19464e3623c119c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec130a8f8a34f5380c52bfc0297528a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10570.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7062919d7dff4577bfb31e715ad77d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e7165fd60d4f3d83d76a50f3e53acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# def get_just_x_or_y_train_dev_dataset(just, DATA_DIR, **kw):\n",
    "#     \"\"\" get x or y datset. \"\"\"\n",
    "#     max_length = kw['max_seq_length']\n",
    "#     tokenizer = kw['tokenizer']\n",
    "#     config = kw['config']\n",
    "# pyarrow.lib.ArrowInvalid: Tried reading schema message, was null or length 0\n",
    "\n",
    "if just == 'x':\n",
    "    subset_of_inputs = {\n",
    "            \"input_ids\",\n",
    "            \"attention_mask\",\n",
    "            \"decoder_input_ids\",\n",
    "            \"decoder_attention_mask\",\n",
    "            # \"lm_labels\"\n",
    "            }\n",
    "elif just == 'y':\n",
    "    subset_of_inputs = {\n",
    "            \"lm_labels\",\n",
    "            }\n",
    "elif isinstance(just, list):\n",
    "    subset_of_inputs = set(just)\n",
    "else:\n",
    "    raise NotImplementedError()\n",
    "\n",
    "# Define all preprocessing here\n",
    "\n",
    "# process the examples in input and target text format and the eos token at the end\n",
    "def add_eos_to_examples(example):\n",
    "    example['input_text'] = 'question: %s  context: %s </s>' % (\n",
    "        example['question'], example['context'])\n",
    "    example['target_text'] = '%s </s>' % example['answers']['text'][0]\n",
    "    return example\n",
    "\n",
    "# tokenize the examples\n",
    "# NOTE: they use global tokenizer\n",
    "\n",
    "def convert_to_features(example_batch):\n",
    "    input_encodings = tokenizer.batch_encode_plus(\n",
    "        example_batch['input_text'],\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length\n",
    "    )  # NOTE: I think this could be changed to 384 like bert to save memory.\n",
    "    target_encodings = tokenizer.batch_encode_plus(\n",
    "        example_batch['target_text'],\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        max_length=16)\n",
    "\n",
    "    encodings = {\n",
    "        'input_ids': input_encodings['input_ids'],\n",
    "        'attention_mask': input_encodings['attention_mask'],\n",
    "        'target_ids': target_encodings['input_ids'],\n",
    "        'target_attention_mask': target_encodings['attention_mask']\n",
    "    }\n",
    "    return encodings\n",
    "\n",
    "def preproc(ds):\n",
    "    input_ids = ds['input_ids']\n",
    "    lm_labels = ds['target_ids']\n",
    "    attention_mask = ds['attention_mask']\n",
    "    decoder_attention_mask = ds['target_attention_mask']\n",
    "\n",
    "    input_ids = torch.tensor(input_ids) # .unsqueeze_(0)\n",
    "    lm_labels = torch.tensor(lm_labels) # .unsqueeze_(0)\n",
    "    attention_mask = torch.tensor(attention_mask) # .unsqueeze_(0)\n",
    "    decoder_attention_mask = torch.tensor(decoder_attention_mask) # .unsqueeze_(0)\n",
    "\n",
    "    lm_labels[lm_labels[:, :] == 0] = -100\n",
    "\n",
    "    decoder_input_ids = _shift_right(config, lm_labels)\n",
    "\n",
    "    precompute_masks = getattr(config, \"precomputed_masks\", False)\n",
    "    if precompute_masks:\n",
    "        # print(\"-I- precomputing t5 masks on CPU\", end =\"...\")\n",
    "        inverted_encoder_attention_mask = get_inverted_encoder_attention_mask(input_ids.size(),attention_mask,attention_mask.device)\n",
    "        attention_mask = get_attention_mask(input_ids.size(),attention_mask,attention_mask.device,is_decoder=False)    \n",
    "        decoder_attention_mask = get_attention_mask(decoder_input_ids.size(),decoder_attention_mask,decoder_attention_mask.device,is_decoder=True)\n",
    "        # print(\"-I- done\")\n",
    "    else:\n",
    "        # print(\"-W- preprocessing will happen inside the model...\")\n",
    "        inverted_encoder_attention_mask = None\n",
    "        decoder_attention_mask = None\n",
    "\n",
    "    # Now, we order according to signature\n",
    "    # input_ids,\n",
    "    # attention_mask=None,\n",
    "    # decoder_input_ids=None,\n",
    "    # decoder_attention_mask=None,\n",
    "    # inverted_encoder_attention_mask=None,\n",
    "    # lm_labels=None\n",
    "\n",
    "    d = {}\n",
    "    d['input_ids'] = input_ids\n",
    "    d['attention_mask'] = attention_mask\n",
    "    d['decoder_input_ids'] = decoder_input_ids\n",
    "    d['decoder_attention_mask'] = decoder_attention_mask\n",
    "    d['inverted_encoder_attention_mask'] = inverted_encoder_attention_mask\n",
    "    d['lm_labels'] = lm_labels\n",
    "\n",
    "    # too lazy to do it selectivly...\n",
    "    keys = tuple(d.keys())\n",
    "    for k in keys:\n",
    "        if k not in subset_of_inputs:\n",
    "            del d[k]\n",
    "\n",
    "    keys = tuple(d.keys())\n",
    "    for k in keys:\n",
    "        if d[k] is None:\n",
    "            del d[k]\n",
    "\n",
    "    keys = tuple(d.keys())\n",
    "    for k in keys:\n",
    "    #     # d[k] = list(d[k])\n",
    "    #    d[k].squeeze_(0)\n",
    "        d[k] = d[k].tolist()\n",
    "\n",
    "    return d\n",
    "\n",
    "\n",
    "# TODO: allow squad2\n",
    "train_dataset = nlp.load_dataset('squad', split=\"train[:1%]\")\n",
    "# train_dataset.cleanup_cache_files()  # Returns the number of removed cache files\n",
    "train_dataset = train_dataset.map(add_eos_to_examples, load_from_cache_file=False)\n",
    "train_dataset = train_dataset.map(convert_to_features, batched=True, load_from_cache_file=False)\n",
    "# train_dataset.set_format(type='torch', columns=None)\n",
    "\n",
    "# for i in range(len(train_dataset)):\n",
    "#     train_dataset[i] = preproc(train_dataset[i])\n",
    "\n",
    "train_dataset = train_dataset.map(preproc, batched=True, load_from_cache_file=False)\n",
    "train_dataset.set_format(type='torch', columns=just)\n",
    " \n",
    "\n",
    "dev_dataset = nlp.load_dataset('squad', split=nlp.Split.VALIDATION)\n",
    "dev_dataset = dev_dataset.map(add_eos_to_examples, load_from_cache_file=False)\n",
    "dev_dataset = dev_dataset.map(convert_to_features, batched=True, load_from_cache_file=False)\n",
    "# dev_dataset.set_format(type='torch', columns=None)\n",
    "dev_dataset = dev_dataset.map(preproc, batched=True, load_from_cache_file=False)\n",
    "dev_dataset.set_format(type='torch', columns=just)\n",
    "\n",
    "# TODO: evaluation (see squad.py)\n",
    "\n",
    "# def set_eval(trainer):\n",
    "#     pass\n",
    "#     # trainer.features = features\n",
    "#     # trainer.statistics.evaluate_squad = types.MethodType(\n",
    "#     #    evaluate_squad, trainer.statistics)\n",
    "\n",
    "# return train_dataset, dev_dataset, set_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [i for i in dev_dataset.column_names if i not in subset_of_inputs]\n",
    "dev_dataset.drop(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attention_mask']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(features: {'answers': {'answer_start': [Value(dtype='int64', id=None)], 'text': [Value(dtype='string', id=None)]}, 'context': Value(dtype='string', id=None), 'id': Value(dtype='string', id=None), 'input_text': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'target_text': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'input_ids': [Value(dtype='int64', id=None)], 'attention_mask': [[[Value(dtype='float64', id=None)]]], 'target_ids': [Value(dtype='int64', id=None)], 'target_attention_mask': [Value(dtype='int64', id=None)], 'decoder_input_ids': [Value(dtype='int64', id=None)]}, num_rows: 10570)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(dev_dataset, \"dev_dataset.pt\")\n",
    "torch.load(\"dev_dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [i for i in train_dataset.column_names if i not in subset_of_inputs]\n",
    "train_dataset.drop(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(features: {'answers': {'answer_start': [Value(dtype='int64', id=None)], 'text': [Value(dtype='string', id=None)]}, 'context': Value(dtype='string', id=None), 'id': Value(dtype='string', id=None), 'input_text': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'target_text': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'input_ids': [Value(dtype='int64', id=None)], 'attention_mask': [[[Value(dtype='float64', id=None)]]], 'target_ids': [Value(dtype='int64', id=None)], 'target_attention_mask': [Value(dtype='int64', id=None)], 'decoder_input_ids': [Value(dtype='int64', id=None)]}, num_rows: 10570)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(dev_dataset, \"train_dataset.pt\")\n",
    "torch.load(\"train_dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cache_file_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m Find a unique name from the filenames, kwargs and the function \n",
       "\u001b[0;31mFile:\u001b[0m      /home_local/saareliad/miniconda3/envs/py38/lib/python3.8/site-packages/nlp/arrow_dataset.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp.Dataset._get_cache_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine with partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_config , partition = models.cfg_to_model.get_partitioning(internal_transformer_config, 2, 16, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6293504"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in partition.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "just = list(pipe_config.get_dataset_inputs_for_stage(2).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attention_mask']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import t5_squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = t5_squad.get_just_x_or_y_train_dev_dataset(just, None, **dict(tokenizer=tokenizer, config=config, max_seq_length=max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading from cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = torch.load(\"/home_local/saareliad/data/cache_val.t5_squad_just_FULL.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(features: {'answers': {'answer_start': [Value(dtype='int64', id=None)], 'text': [Value(dtype='string', id=None)]}, 'context': Value(dtype='string', id=None), 'id': Value(dtype='string', id=None), 'input_text': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'target_text': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'input_ids': [Value(dtype='int64', id=None)], 'attention_mask': [[[Value(dtype='float64', id=None)]]], 'target_ids': [Value(dtype='int64', id=None)], 'target_attention_mask': [Value(dtype='int64', id=None)], 'decoder_input_ids': [Value(dtype='int64', id=None)]}, num_rows: 10570)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.set_format(type='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.set_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(tmp[0]['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.set_format(type='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.set_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['answers',\n",
       " 'context',\n",
       " 'id',\n",
       " 'input_text',\n",
       " 'question',\n",
       " 'target_text',\n",
       " 'title',\n",
       " 'input_ids',\n",
       " 'attention_mask',\n",
       " 'target_ids',\n",
       " 'target_attention_mask',\n",
       " 'decoder_input_ids']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.drop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = torch.load(\"/home_local/saareliad/data/cache_val.t5_squad_just_FULL.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['answers', 'context', 'id', 'input_text', 'question', 'target_text', 'title', 'input_ids', 'attention_mask', 'target_ids', 'target_attention_mask', 'decoder_input_ids', 'decoder_attention_mask', 'inverted_encoder_attention_mask', 'lm_labels'])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [i for i in tmp.column_names if i not in ['decoder_attention_mask', 'inverted_encoder_attention_mask', 'lm_labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.drop(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['decoder_attention_mask', 'inverted_encoder_attention_mask', 'lm_labels'])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [torch.tensor(tmp[v]) for v in tmp.column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-732010f46276>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home_local/saareliad/miniconda3/envs/py38/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home_local/saareliad/miniconda3/envs/py38/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'generator' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "tds = torch.utils.data.TensorDataset(torch.tensor(tmp[v]) for v in tmp.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor(tmp['decoder_attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['answers', 'context', 'id', 'input_text', 'question', 'target_text', 'title', 'input_ids', 'attention_mask', 'target_ids', 'target_attention_mask', 'decoder_input_ids'])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.reset_format()\n",
    "tmp[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tds.tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "def foo(*a):\n",
    "    for i in a:\n",
    "        print(i)\n",
    "        \n",
    "foo(*range(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from cache: small\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.2397,  0.8943,  1.0996,  0.8660, -0.3662,  1.7107, -0.9624, -0.1194,\n",
       "         0.8584,  0.6684])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TorchCache:\n",
    "    def __init__(self, cache_name, overwrite=False):\n",
    "        self.cache_name = cache_name\n",
    "        self.exists = os.path.exists(cache_name)\n",
    "        self.overwrite = overwrite\n",
    "        self.v = None\n",
    "        \n",
    "    def __enter__(self):\n",
    "        if self.exists:\n",
    "            print(f\"loading from cache: {self.cache_name}\")\n",
    "            self.v = torch.load(self.cache_name)\n",
    "        else:\n",
    "            print(f\"computing value for {self.cache_name}\")\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        if not self.exists or self.overwrite:\n",
    "            print(f\"saving to cache: {self.cache_name}\")            \n",
    "            assert self.v is not None, \"You should enter a value\"\n",
    "            torch.save(self.v, self.cache_name)\n",
    "\n",
    "def compute_and_cache(compute_function, cache_name, overwrite=False, *args, **kw):\n",
    "    \"\"\"\n",
    "    Compute or load from cache, optionaly save results to cache.\n",
    "    Return computed value\n",
    "    Examples:\n",
    "        # compute big\n",
    "        # compute_and_cache(lambda: torch.ones(10), \"big\")\n",
    "        \n",
    "        # compute big, then small\n",
    "        # compute_and_cache(lambda: torch.randn(10) * compute_and_cache(lambda: torch.ones(10), \"big\"), \"small\")\n",
    "    \"\"\"\n",
    "\n",
    "    with TorchCache(cache_name) as big:\n",
    "        if not big.exists:\n",
    "            big.v = compute_function(*args, **kw)\n",
    "    return big.v\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home_local/saareliad/data/cache_val.t5_squad_just_lm_labels_inverted_encoder_attention_mask_decoder_attention_mask.pt\n",
      "/home_local/saareliad/data/cache_val.t5_squad_just_inverted_encoder_attention_mask_lm_labels_decoder_attention_mask.pt\n",
      "/home_local/saareliad/data/cache_val.t5_squad_just_input_ids_decoder_input_ids_attention_mask.pt\n",
      "/home_local/saareliad/data/cache_val.t5_squad_just_input_ids_attention_mask_decoder_input_ids.pt\n",
      "/home_local/saareliad/data/cache_val.t5_squad_just_FULL.pt\n",
      "/home_local/saareliad/data/cache_val.t5_squad_just_decoder_input_ids_input_ids_attention_mask.pt\n",
      "/home_local/saareliad/data/cache_val.t5_squad_just_decoder_attention_mask_inverted_encoder_attention_mask_lm_labels.pt\n",
      "/home_local/saareliad/data/cache_val.t5_squad_just_attention_mask.pt\n",
      "/home_local/saareliad/data/cache_train.t5_squad_just_lm_labels_inverted_encoder_attention_mask_decoder_attention_mask.pt\n",
      "/home_local/saareliad/data/cache_train.t5_squad_just_inverted_encoder_attention_mask_lm_labels_decoder_attention_mask.pt\n",
      "/home_local/saareliad/data/cache_train.t5_squad_just_input_ids_decoder_input_ids_attention_mask.pt\n",
      "/home_local/saareliad/data/cache_train.t5_squad_just_input_ids_attention_mask_decoder_input_ids.pt\n",
      "/home_local/saareliad/data/cache_train.t5_squad_just_FULL.pt\n",
      "/home_local/saareliad/data/cache_train.t5_squad_just_decoder_input_ids_input_ids_attention_mask.pt\n",
      "/home_local/saareliad/data/cache_train.t5_squad_just_decoder_attention_mask_inverted_encoder_attention_mask_lm_labels.pt\n",
      "/home_local/saareliad/data/cache_train.t5_squad_just_attention_mask.pt\n"
     ]
    }
   ],
   "source": [
    "!ls -r /home_local/saareliad/data/cache_*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_squad_just_decoder_attention_mask_inverted_encoder_attention_mask_lm_labels\n",
    "t5_squad_just_inverted_encoder_attention_mask_lm_labels_decoder_attention_mask\n",
    "t5_squad_just_lm_labels_inverted_encoder_attention_mask_decoder_attention_mask\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m           /home_local/saareliad/miniconda3/envs/py38/lib/python3.8/site-packages/torch/__init__.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.dtype??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
