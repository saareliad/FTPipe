{
  "batch_dim": 0,
  "depth": -1,
  "basic_blocks": [
    "torch.nn.modules.sparse.Embedding",
    "models.normal.NLP_models.stateless.StatelessEmbedding",
    "torch.nn.modules.normalization.LayerNorm",
    "torch.nn.modules.dropout.Dropout",
    "models.normal.NLP_models.stateless.StatelessLinear",
    "transformers.modeling_utils.Conv1D"
  ],
  "model_inputs": {
    "input0": {
      "shape": [1, 1024],
      "dtype": "torch.int64",
      "is_batched": true
    },
    "input1": {
      "shape": [1, 1024],
      "dtype": "torch.int64",
      "is_batched": true
    }
  },
  "model_outputs": {
    "GPT2LMHeadModel/aten::nll_loss4189": {
      "shape": [1],
      "dtype": "torch.float32",
      "is_batched": false
    }
  },
  "stages": {
    "0": {
      "inputs": {
        "input0": {
          "shape": [1, 1024],
          "dtype": "torch.int64",
          "is_batched": true
        }
      },
      "outputs": {
        "GPT2LMHeadModel/GPT2Model[transformer]/Block[0]/aten::add5152": {
          "shape": [1, 1024, 768],
          "dtype": "torch.float32",
          "is_batched": true
        },
        "GPT2LMHeadModel/GPT2Model[transformer]/Block[1]/Attention[attn]/Dropout[resid_dropout]": {
          "shape": [1, 1024, 768],
          "dtype": "torch.float32",
          "is_batched": true
        },
        "GPT2LMHeadModel/Parameter[w_wte]": {
          "shape": [50257, 768],
          "dtype": "torch.float32",
          "is_batched": false
        }
      },
      "stage_cls": "models.partitioned.gpt2.gpt2_lmhead.Partition0",
      "devices": ["cpu"]
    },
    "1": {
      "inputs": {
        "GPT2LMHeadModel/GPT2Model[transformer]/Block[0]/aten::add5152": {
          "shape": [1, 1024, 768],
          "dtype": "torch.float32",
          "is_batched": true
        },
        "GPT2LMHeadModel/GPT2Model[transformer]/Block[1]/Attention[attn]/Dropout[resid_dropout]": {
          "shape": [1, 1024, 768],
          "dtype": "torch.float32",
          "is_batched": true
        }
      },
      "outputs": {
        "GPT2LMHeadModel/GPT2Model[transformer]/Block[4]/aten::add6312": {
          "shape": [1, 1024, 768],
          "dtype": "torch.float32",
          "is_batched": true
        },
        "GPT2LMHeadModel/GPT2Model[transformer]/Block[5]/Attention[attn]/aten::matmul6472": {
          "shape": [1, 12, 1024, 64],
          "dtype": "torch.float32",
          "is_batched": true
        }
      },
      "stage_cls": "models.partitioned.gpt2.gpt2_lmhead.Partition1",
      "devices": ["cpu"]
    },
    "2": {
      "inputs": {
        "GPT2LMHeadModel/GPT2Model[transformer]/Block[4]/aten::add6312": {
          "shape": [1, 1024, 768],
          "dtype": "torch.float32",
          "is_batched": true
        },
        "GPT2LMHeadModel/GPT2Model[transformer]/Block[5]/Attention[attn]/aten::matmul6472": {
          "shape": [1, 12, 1024, 64],
          "dtype": "torch.float32",
          "is_batched": true
        }
      },
      "outputs": {
        "GPT2LMHeadModel/GPT2Model[transformer]/Block[8]/LayerNorm[ln_2]": {
          "shape": [1, 1024, 768],
          "dtype": "torch.float32",
          "is_batched": true
        },
        "GPT2LMHeadModel/GPT2Model[transformer]/Block[8]/aten::add7396": {
          "shape": [1, 1024, 768],
          "dtype": "torch.float32",
          "is_batched": true
        }
      },
      "stage_cls": "models.partitioned.gpt2.gpt2_lmhead.Partition2",
      "devices": ["cpu"]
    },
    "3": {
      "inputs": {
        "GPT2LMHeadModel/GPT2Model[transformer]/Block[8]/LayerNorm[ln_2]": {
          "shape": [1, 1024, 768],
          "dtype": "torch.float32",
          "is_batched": true
        },
        "GPT2LMHeadModel/GPT2Model[transformer]/Block[8]/aten::add7396": {
          "shape": [1, 1024, 768],
          "dtype": "torch.float32",
          "is_batched": true
        }
      },
      "outputs": {
        "GPT2LMHeadModel/GPT2Model[transformer]/Block[11]/aten::add8342": {
          "shape": [1, 1024, 768],
          "dtype": "torch.float32",
          "is_batched": true
        }
      },
      "stage_cls": "models.partitioned.gpt2.gpt2_lmhead.Partition3",
      "devices": ["cpu"]
    },
    "4": {
      "inputs": {
        "GPT2LMHeadModel/GPT2Model[transformer]/Block[11]/aten::add8342": {
          "shape": [1, 1024, 768],
          "dtype": "torch.float32",
          "is_batched": true
        },
        "GPT2LMHeadModel/Parameter[w_wte]": {
          "shape": [50257, 768],
          "dtype": "torch.float32",
          "is_batched": false
        },
        "input1": {
          "shape": [1, 1024],
          "dtype": "torch.int64",
          "is_batched": true
        }
      },
      "outputs": {
        "GPT2LMHeadModel/aten::nll_loss4189": {
          "shape": [1],
          "dtype": "torch.float32",
          "is_batched": false
        }
      },
      "stage_cls": "models.partitioned.gpt2.gpt2_lmhead.Partition4",
      "devices": ["cpu"]
    }
  }
}
