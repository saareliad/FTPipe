{
    "batch_dim": 0,
    "depth": 10000,
    "basic_blocks": [
        "torch.nn.modules.sparse.Embedding",
        "torch.nn.modules.normalization.LayerNorm",
        "torch.nn.modules.dropout.Dropout",
        "transformers.modeling_utils.Conv1D",
        "torch.nn.modules.linear.Linear"
    ],
    "model_inputs": {
        "input0": {
            "shape": [
                1,
                1024
            ],
            "dtype": "torch.int64",
            "is_batched": true
        },
        "input1": {
            "shape": [
                1,
                1024
            ],
            "dtype": "torch.int64",
            "is_batched": true
        }
    },
    "model_outputs": {
        "GPT2LMHeadModel/aten::nll_loss16398": {
            "shape": [
                1
            ],
            "dtype": "torch.float32",
            "is_batched": false
        }
    },
    "stages": {
        "0": {
            "inputs": {
                "input0": {
                    "shape": [
                        1,
                        1024
                    ],
                    "dtype": "torch.int64",
                    "is_batched": true
                }
            },
            "outputs": {
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[5]/LayerNorm[ln_2]": {
                    "shape": [
                        1,
                        1024,
                        1600
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                },
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[5]/aten::add19943": {
                    "shape": [
                        1,
                        1024,
                        1600
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                }
            },
            "stage_cls": "results.gpt2xl_untied_p8._gpt2_xl_p8_lm_untied_r1.Partition0",
            "devices": [
                "cpu"
            ]
        },
        "1": {
            "inputs": {
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[5]/LayerNorm[ln_2]": {
                    "shape": [
                        1,
                        1024,
                        1600
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                },
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[5]/aten::add19943": {
                    "shape": [
                        1,
                        1024,
                        1600
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                }
            },
            "outputs": {
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[10]/aten::add20887": {
                    "shape": [
                        1,
                        1024,
                        1600
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                },
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[11]/Attention[attn]/aten::matmul21017": {
                    "shape": [
                        1,
                        25,
                        1024,
                        64
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                }
            },
            "stage_cls": "results.gpt2xl_untied_p8._gpt2_xl_p8_lm_untied_r1.Partition1",
            "devices": [
                "cpu"
            ]
        },
        "2": {
            "inputs": {
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[10]/aten::add20887": {
                    "shape": [
                        1,
                        1024,
                        1600
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                },
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[11]/Attention[attn]/aten::matmul21017": {
                    "shape": [
                        1,
                        25,
                        1024,
                        64
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                }
            },
            "outputs": {
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[16]/aten::add21991": {
                    "shape": [
                        1,
                        1024,
                        1600
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                },
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[17]/Attention[attn]/aten::permute22031": {
                    "shape": [
                        1,
                        25,
                        1024,
                        64
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                },
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[17]/Attention[attn]/aten::permute22054": {
                    "shape": [
                        1,
                        25,
                        64,
                        1024
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                },
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[17]/Attention[attn]/aten::view22071": {
                    "shape": [
                        1,
                        1024,
                        25,
                        64
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                }
            },
            "stage_cls": "results.gpt2xl_untied_p8._gpt2_xl_p8_lm_untied_r1.Partition2",
            "devices": [
                "cpu"
            ]
        },
        "3": {
            "inputs": {
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[16]/aten::add21991": {
                    "shape": [
                        1,
                        1024,
                        1600
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                },
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[17]/Attention[attn]/aten::permute22031": {
                    "shape": [
                        1,
                        25,
                        1024,
                        64
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                },
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[17]/Attention[attn]/aten::permute22054": {
                    "shape": [
                        1,
                        25,
                        64,
                        1024
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                },
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[17]/Attention[attn]/aten::view22071": {
                    "shape": [
                        1,
                        1024,
                        25,
                        64
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                }
            },
            "outputs": {
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[22]/aten::add23095": {
                    "shape": [
                        1,
                        1024,
                        1600
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                },
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[23]/Attention[attn]/aten::permute23231": {
                    "shape": [
                        1,
                        1024,
                        25,
                        64
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                }
            },
            "stage_cls": "results.gpt2xl_untied_p8._gpt2_xl_p8_lm_untied_r1.Partition3",
            "devices": [
                "cpu"
            ]
        },
        "4": {
            "inputs": {
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[22]/aten::add23095": {
                    "shape": [
                        1,
                        1024,
                        1600
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                },
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[23]/Attention[attn]/aten::permute23231": {
                    "shape": [
                        1,
                        1024,
                        25,
                        64
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                }
            },
            "outputs": {
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[28]/aten::add24199": {
                    "shape": [
                        1,
                        1024,
                        1600
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                },
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[29]/Attention[attn]/aten::view24355": {
                    "shape": [
                        1,
                        1024,
                        1600
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                }
            },
            "stage_cls": "results.gpt2xl_untied_p8._gpt2_xl_p8_lm_untied_r1.Partition4",
            "devices": [
                "cpu"
            ]
        },
        "5": {
            "inputs": {
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[28]/aten::add24199": {
                    "shape": [
                        1,
                        1024,
                        1600
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                },
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[29]/Attention[attn]/aten::view24355": {
                    "shape": [
                        1,
                        1024,
                        1600
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                }
            },
            "outputs": {
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[34]/aten::add25303": {
                    "shape": [
                        1,
                        1024,
                        1600
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                },
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[35]/Attention[attn]/Dropout[resid_dropout]": {
                    "shape": [
                        1,
                        1024,
                        1600
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                }
            },
            "stage_cls": "results.gpt2xl_untied_p8._gpt2_xl_p8_lm_untied_r1.Partition5",
            "devices": [
                "cpu"
            ]
        },
        "6": {
            "inputs": {
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[34]/aten::add25303": {
                    "shape": [
                        1,
                        1024,
                        1600
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                },
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[35]/Attention[attn]/Dropout[resid_dropout]": {
                    "shape": [
                        1,
                        1024,
                        1600
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                }
            },
            "outputs": {
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[41]/aten::add26591": {
                    "shape": [
                        1,
                        1024,
                        1600
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                }
            },
            "stage_cls": "results.gpt2xl_untied_p8._gpt2_xl_p8_lm_untied_r1.Partition6",
            "devices": [
                "cpu"
            ]
        },
        "7": {
            "inputs": {
                "GPT2LMHeadModel/GPT2Model[transformer]/Block[41]/aten::add26591": {
                    "shape": [
                        1,
                        1024,
                        1600
                    ],
                    "dtype": "torch.float32",
                    "is_batched": true
                },
                "input1": {
                    "shape": [
                        1,
                        1024
                    ],
                    "dtype": "torch.int64",
                    "is_batched": true
                }
            },
            "outputs": {
                "GPT2LMHeadModel/aten::nll_loss16398": {
                    "shape": [
                        1
                    ],
                    "dtype": "torch.float32",
                    "is_batched": false
                }
            },
            "stage_cls": "results.gpt2xl_untied_p8._gpt2_xl_p8_lm_untied_r1.Partition7",
            "devices": [
                "cpu"
            ]
        }
    }
}